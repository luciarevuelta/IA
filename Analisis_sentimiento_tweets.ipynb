{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412d277d-ad48-446f-86cf-c458994117e1",
   "metadata": {},
   "source": [
    "## Fase 1: Importar las dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df22698-a8cf-4a18-b7f9-bfbbc847d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re #libreria expresiones regulares\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup # trabajar texto codificado en varios formatos(metadatos, XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8410388-f92c-4214-9229-5c1eab2b53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers #de la sublibrería keras saco las capas (layers) \n",
    "import tensorflow_datasets as tfds #dentro de tfds hay una herramienta muy útil llamada tokenizador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189c395-d4ba-4303-8713-beda66f90945",
   "metadata": {},
   "source": [
    "## Fase 2: Pre Procesado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6441b1c8-6b67-46d9-950d-c252f14108e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"] #no tiene cabecera el csv\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    \"./data/train.csv\",\n",
    "    header = None,\n",
    "    names = cols,\n",
    "    engine = \"python\",\n",
    "    encoding = \"latin1\"\n",
    ")\n",
    "\n",
    "test_data = pd.read_csv(\n",
    "    \"./data/test.csv\",\n",
    "    header = None,\n",
    "    names = cols,\n",
    "    engine = \"python\", #engine : motor de carga python\n",
    "    encoding = \"latin1\" #codificación estándar idiomas europeos/americanos (derivados del latin).\n",
    ")                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60674e78-81c9-4d66-8453-93180c5061a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1599995          4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996          4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997          4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998          4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999          4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d80a7d2-f0e7-4370-aefb-44e0f16bf19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2</td>\n",
       "      <td>14072</td>\n",
       "      <td>Sun Jun 14 04:31:43 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>proggit</td>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>14073</td>\n",
       "      <td>Sun Jun 14 04:32:17 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>sam33r</td>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>14074</td>\n",
       "      <td>Sun Jun 14 04:36:34 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>iamtheonlyjosie</td>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>14075</td>\n",
       "      <td>Sun Jun 14 21:36:07 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>plutopup7</td>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>14076</td>\n",
       "      <td>Sun Jun 14 21:36:17 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>captain_pete</td>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment     id                          date  query             user  \\\n",
       "493          2  14072  Sun Jun 14 04:31:43 UTC 2009  latex          proggit   \n",
       "494          0  14073  Sun Jun 14 04:32:17 UTC 2009  latex           sam33r   \n",
       "495          4  14074  Sun Jun 14 04:36:34 UTC 2009  latex  iamtheonlyjosie   \n",
       "496          0  14075  Sun Jun 14 21:36:07 UTC 2009   iran        plutopup7   \n",
       "497          0  14076  Sun Jun 14 21:36:17 UTC 2009   iran     captain_pete   \n",
       "\n",
       "                                                  text  \n",
       "493  Ask Programming: LaTeX or InDesign?: submitted...  \n",
       "494  On that note, I hate Word. I hate Pages. I hat...  \n",
       "495  Ahhh... back in a *real* text editing environm...  \n",
       "496  Trouble in Iran, I see. Hmm. Iran. Iran so far...  \n",
       "497  Reading the tweets coming out of Iran... The w...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tail(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b06a2e5-ad2c-44cf-bf5a-ae3b68ca7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9235f48-8846-4332-89fb-744b4ffc5e7f",
   "metadata": {},
   "source": [
    "## Pre Procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe5dd7-8ccc-43ab-87db-2c70f3671d59",
   "metadata": {},
   "source": [
    "### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2ee104-d821-41c5-9654-57659d4e27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['id','date','query','user'], \n",
    "                 axis = 1, #eliminar solo las columnas // axis = 0 (elimina filas)\n",
    "                 inplace = True) #quiero la versión de data sin las columnas eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be255d85-0277-422a-a5e8-620d22b46565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e007a775-90dc-4bcc-b070-38b63472a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = BeautifulSoup(tweet,\"lxml\").get_text()\n",
    "    #eliminamos la @ y su mención\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet) #cualquier cosa que empiece por @ y seguido de un número o letra \n",
    "    #(usuariotwitter) en cualquier orden. Lo reemplazará por un espacio en blanco ' '.\n",
    "    \n",
    "    #eliminamos los links de las URLs\n",
    "    tweet =re.sub(r\"https?://[A-Za-z0-9./]+\",' ', tweet) # ?s: el caracter s es opcional. \n",
    "                                                         #./ : incluido las barras (en las URLs las hay)\n",
    "                                                         # Lo reemplaza por un espacio en blanco.\n",
    "            \n",
    "    # nos quedamos solo con los caracteres\n",
    "    tweet = re.sub(r\"[^a-zA-Z.!?']\",' ', tweet)          #eliminamos todos los caracteres a excepción (^):\n",
    "                                                         # a-z, A-Z, ., !, ? '. Lo demás se reemplaza por espacio blanco.\n",
    "    \n",
    "    #eliminamos espacios en blanco adicionales que he creado\n",
    "    tweet = re.sub(r\" +\", ' ',tweet)                     # busco al menos dos espacios en blanco seguidos uno detrás del otro\n",
    "                                                         # y los reemplazo por uno solo.\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "481d198b-d658-4f23-a143-5cc8be2089da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_clean = [clean_tweet(tweet) for tweet in data.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84f47361-e5eb-44d4-a1e6-8bed2e6ebeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca46f337-7760-4ee5-adf9-b718eaffa719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.sentiment) #conjunto de valores diferentes que hay en la columna\n",
    "#el 0 es negativo y el 4 es positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac0ddc1a-d625-4fff-a03e-2a84d99ccce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = data.sentiment.values #extraigo los valores de nuestro data\n",
    "data_labels[data_labels == 4] = 1 #filtro las filas donde data_labels = 4 y lo cambio por 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7999c3c-cb41-4f8e-b2fc-9f2b788ec554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca5b7515-10b8-4a61-a5b7-e10015ecc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_clean  (corpus: lista de todo el texto que se quiere analizar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5cd44-98b7-4659-b153-3af30c8941b5",
   "metadata": {},
   "source": [
    "### Tokenización.\n",
    "\n",
    "Ahora nuestro data es una lista se caracteres conformada por palabras en inglés. Lo que quiero hacer ahora es obtener una lista de números y cada uno de los número representará una palabra diferente. Existe una herramienta en TensorFlow que nos permite hacerlo automáticamente. Vamos a construir para cada frase la lista de palabras que contiene. Transformaremos la frase de palabras entendibles por un humano a una lista de número donde cada número referencia a una palabra única."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dc64fd1-be6b-490b-b598-7439fc4e5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus( #construir tokenizador a partir de un corpus\n",
    "    data_clean, target_vocab_size = 2**16 #lista de strings y tamaño del vocabulario 2^16.\n",
    ")\n",
    "data_inputs = [tokenizer.encode(sentence) for sentence in data_clean] #para cada una de las frase del dataset limpio, le pido que me la codifique\n",
    "# me devolverá una lista de números donde cada uno de los número corresponde a una palabra diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c04b6e99-c82f-471a-af0a-86a65a5871ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed023a-0e8b-4673-a15f-e7d64cd383e6",
   "metadata": {},
   "source": [
    "### Padding\n",
    "El entrenamiento en inteligencia artificial muchas veces se hace por bloques que queremos que tengan la misma longitud. Estos bloques permiten hacer un machine learning un aprendizaje que en vez de suministrarle frase a frase se le otorga un conjunto de elementos. Añade 0 al final de cada una de las frases ya que el tokenizador no usa el 0 (no significada nada) y así quedan de la misma longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7752f7e4-cd94-4bd1-a30e-ad8720d751b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max([len(sentence) for sentence in data_inputs])\n",
    "data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n",
    "                                                            value = 0,\n",
    "                                                            padding = \"post\",\n",
    "                                                            maxlen = MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b35c28d-c88a-4816-b178-f2bdf816645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65316,  1570,   113, ...,     0,     0,     0],\n",
       "       [   11,  1090,    23, ...,     0,     0,     0],\n",
       "       [65316,     3, 41563, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  927,    12,   229, ...,     0,     0,     0],\n",
       "       [  366,   337,  1309, ...,     0,     0,     0],\n",
       "       [  181, 51236,     0, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79294297-1d45-4567-af93-12febffb397b",
   "metadata": {},
   "source": [
    "### Dividimos en los conjuntos de entrenamiento y testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c109ab4-514d-4f45-a69e-edb45943cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.random.randint(0,800000, 8000) #los identificadores de test entre 0 y 800000 elijo 8000 filas (negativos) (números aleatorios).\n",
    "test_idx = np.concatenate((test_idx, test_idx+800000)) # le sumo 800000 me encuentro en la sección de los positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72941476-4968-404a-9681-e4bc4a5bfe1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 505773,  377058,  428258, ...,  965923,  967503, 1482645])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fb2ba8f-6c5e-40d9-b965-c0317b48ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = data_inputs[test_idx]\n",
    "test_labels = data_labels[test_idx]\n",
    "train_inputs = np.delete(data_inputs, test_idx, axis = 0) #se borra por filas\n",
    "train_labels = np.delete(data_labels, test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ccaf71-dfe9-4be2-a5f9-0f4a33990cd5",
   "metadata": {},
   "source": [
    "## Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f393fd3-f8c9-4a15-a83a-0d828a4be4ae",
   "metadata": {},
   "source": [
    "DCNN: deep convolutional neural network que hereda de tensorflow.keras.Model \n",
    "Vamos a heredad de esa clase que ya habíamos importado al inicio de todo. Lo primero que se hace siempre que heredamos de un modelo keras es definir un método init. Definimos nuestro constructor.\n",
    "\n",
    "vocab_size: tamaño del vocabulario ¿Cuántas palabras queremos manejar? Todavía no lo sabemos y nos lo va a dar el tokenizador.\n",
    "\n",
    "emb_dim: ¿A qué espacio vectorial vamos a embeber nuestra información? 128 números. Cada palabra será embebida a un espacio vectorial de dimensión 128.\n",
    "\n",
    "nb_filters:¿Cuántos filtros vamos a utilizar? Filtros de dos, tres y cuatro palabras. He puesto que habrá 50 de cada uno de ellos.\n",
    "\n",
    "FNN_units: número de neuronas de la DCNN\n",
    "\n",
    "bn_classes: diferentes tipos de categorías (positivo o negativo)\n",
    "\n",
    "dropout_rate: previene overfitting y que algunas neuronas se desactiven mientras otras aprenden. El 10% de las neuronas no transmitirán lo que han aprendido en la fase de entrenamiento.\n",
    "\n",
    "training = False -> Se utilizará para saber si la red neurona tiene que entrenar y por tanto tiene que llevar a cabo la fase de propagación hacia atrás del error y corregir los pesos de la misma o solo se utiliza para lleva a cabo las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a87bf0d-3b77-470c-9109-9002e9fe31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 emb_dim=128,\n",
    "                 nb_filters=50,\n",
    "                 FFN_units=512,\n",
    "                 nb_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"dcnn\"):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size,\n",
    "                                          emb_dim)\n",
    "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
    "                                    kernel_size=2,\n",
    "                                    padding=\"valid\",\n",
    "                                    activation=\"relu\")\n",
    "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                     kernel_size=3,\n",
    "                                     padding=\"valid\",\n",
    "                                     activation=\"relu\")\n",
    "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
    "                                      kernel_size=4,\n",
    "                                      padding=\"valid\",\n",
    "                                      activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D() # No tenemos variable de entrenamiento\n",
    "                                             # así que podemos usar la misma capa \n",
    "                                             # para cada paso de pooling\n",
    "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if nb_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=nb_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaac60c-b2d3-4220-8109-1087e023f0ac",
   "metadata": {},
   "source": [
    "## Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6edc8917-d6fd-47a1-9b72-d56f504d761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size # 65540\n",
    "\n",
    "EMB_DIM = 200\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = 2#len(set(train_labels))\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f441647-5b8a-4988-9496-f390dc796bef",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "821a8936-c64b-4673-b036-7d47421614f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
    "            emb_dim=EMB_DIM,\n",
    "            nb_filters=NB_FILTERS,\n",
    "            FFN_units=FFN_UNITS,\n",
    "            nb_classes=NB_CLASSES,\n",
    "            dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa8d7b0c-e66b-4e77-80b9-96bc7c9795e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NB_CLASSES == 2:\n",
    "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "else:\n",
    "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a5cda9b-af44-4f77-9beb-96456fd74ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/lucia/Escritorio/Curso_Udemy_PNL/CKP\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Último checkpoint restaurado!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4813d7-23bf-4dc8-8f43-5d3592dc1c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 4753/49503 [=>............................] - ETA: 3:49:28 - loss: 0.4680 - accuracy: 0.7763"
     ]
    }
   ],
   "source": [
    "Dcnn.fit(train_inputs,\n",
    "         train_labels,\n",
    "         batch_size=BATCH_SIZE,\n",
    "         epochs=NB_EPOCHS)\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f8df3-c85d-4371-84bc-86f6f9c9d39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d10e01-a3f7-44b8-b9c6-f31b179714b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
